{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The date of the adj file is actually the date of the input data, which represents the first-order network of the next trading day\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Stock Network')\n",
    "\n",
    "\n",
    "parser.add_argument('--prestart_time', type=str, default='2000-01-01')\n",
    "parser.add_argument('--start_time', type=str, default='2004-10-31')\n",
    "parser.add_argument('--end_time', type=str, default='2020-01-01')\n",
    "parser.add_argument('--lagend_time', type=str, default='2020-10-31')\n",
    "parser.add_argument('--save_path', type=str, default='./output')\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4)\n",
    "parser.add_argument('--epochs', type=int, default=400)\n",
    "parser.add_argument('--device', type=str, default='cuda:1')\n",
    "parser.add_argument('--window_size', type=int, default=5)\n",
    "\n",
    "args = parser.parse_args(args=[\n",
    "    '--save_path', './adj_rolling',\n",
    "    '--prestart_time', '2014-06-01',\n",
    "    '--start_time', '2015-01-01',\n",
    "    '--end_time', '2020-01-01',\n",
    "    '--lagend_time', '2020-10-30',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interv_utlis import *\n",
    "from eval_utlis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_pool = []\n",
    "com_path = './company_pool.txt'\n",
    "with open(com_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.replace(',', '')\n",
    "        company_pool.append(line.strip())\n",
    "company_pool.sort()\n",
    "company_pool.append('^gspc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_sel, df = get_uplift_data(company_1=company_pool, args=args)\n",
    "pred_timestamps = list(D.calendar(start_time='2017-01-01', end_time='2020-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_path = args.save_path + '/' + 'corr_lim'\n",
    "if not os.path.exists(corr_path):\n",
    "    os.makedirs(corr_path)\n",
    "\n",
    "ts_bgein = datetime.datetime.strptime('2017-01-01', '%Y-%m-%d')\n",
    "\n",
    "for pred_day in tqdm(pred_timestamps):\n",
    "    if pred_day < ts_bgein:\n",
    "        continue\n",
    "    train_start = (pred_day - relativedelta(years=2)).strftime('%Y-%m-%d')\n",
    "    train_end = (pred_day - relativedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    events = {'train':(train_start, train_end),}\n",
    "\n",
    "    ## correlation\n",
    "    partial_corr = get_corr(events=events, price_df=df, company_sel=company_sel, method=get_interval)\n",
    "\n",
    "    dir_adj = pd.DataFrame(partial_corr, index=company_sel, columns=company_sel)\n",
    "    dir_adj = dir_adj.fillna(value=0)\n",
    "\n",
    "    lim_pos = 0.4\n",
    "    lim_neg = -0.2\n",
    "    dir_adj_np = gen_adj(dir_adj.copy(), lim_pos=lim_pos, lim_neg=lim_neg)\n",
    "\n",
    "    dir_adj_np = np.delete(dir_adj_np, -1, 0)\n",
    "    dir_adj_np = np.delete(dir_adj_np, -1, 1)\n",
    "\n",
    "    np.save(os.path.join(corr_path, pred_day.strftime('%Y-%m-%d')+'.npy'), dir_adj_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_sel.remove('^gspc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## high volume with high positeve return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = args.save_path + '/' + 'hrhv_pos'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "ts_bgein = datetime.datetime.strptime('2017-01-01', '%Y-%m-%d')\n",
    "\n",
    "for pred_day in tqdm(pred_timestamps):\n",
    "    if pred_day < ts_bgein:\n",
    "        continue\n",
    "    train_start = (pred_day - relativedelta(years=2)).strftime('%Y-%m-%d')\n",
    "    train_end = (pred_day - relativedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    events = {'train':(train_start, train_end),}\n",
    "\n",
    "    ## correlation\n",
    "    dir_adj_np = np.load(args.save_path + '/corr_lim/' + pred_day.strftime('%Y-%m-%d') + '.npy')\n",
    "\n",
    "    ## causal\n",
    "    adj_matrix = pd.DataFrame(dir_adj_np, index=company_sel, columns=company_sel,dtype=bool)\n",
    "    inter = events['train']\n",
    "    day_start = get_interval(inter)[0]\n",
    "    day_end = get_interval(inter)[1]\n",
    "    causal_martix = np.zeros_like(adj_matrix, dtype=np.float64)\n",
    "    for comp in company_sel: # target node\n",
    "        i = company_sel.index(comp)\n",
    "        related_comp = adj_matrix.loc[comp][adj_matrix.loc[comp] == True].index.to_list()\n",
    "        if len(related_comp)==0:\n",
    "            continue\n",
    "        df_comp = df.loc[day_start:day_end].loc[(slice(None), related_comp+[comp]), 'feature'].loc[:, 'return']\n",
    "        df_comp = pd.pivot(df_comp.reset_index(),index='datetime', columns='instrument')\n",
    "        df_vol = df.loc[day_start:day_end].loc[(slice(None), related_comp+[comp]), 'feature'].loc[:, '$volume']\n",
    "        df_vol = pd.pivot(df_vol.reset_index(), index='datetime', columns='instrument')\n",
    "        Y = pd.Series(df_comp.loc[:, 'return'][comp].shift(-1), name='Y')\n",
    "        for T_comp in related_comp:\n",
    "            j = company_sel.index(T_comp)\n",
    "            ## volume\n",
    "            T_vol = pd.Series(df_vol.loc[:, '$volume'][T_comp], name='T').copy(deep=True)\n",
    "            lim_vol = T_vol.mean() + 1 * T_vol.std()\n",
    "            cond_pos = T_vol>=lim_vol\n",
    "            T_vol.where(cond_pos, other=0, inplace=True)\n",
    "            T_vol[T_vol>0.01] = 1\n",
    "            T_vol = T_vol.astype('int')\n",
    "            ## return\n",
    "            T_high = pd.Series(df_comp.loc[:, 'return'][T_comp], name='T').copy(deep=True)\n",
    "            lim_low = 0.04\n",
    "            cond_2 = T_high>=lim_low\n",
    "            T_high.where(cond_2, other=0, inplace=True)\n",
    "            T_high[T_high>0.0001] = 1\n",
    "            T_high = T_high.astype('int')\n",
    "\n",
    "            T_0 = T_vol & T_high\n",
    "            if T_0.sum()<5:\n",
    "                continue\n",
    "\n",
    "            df_comp2 = pd.concat([df_comp.loc[:, 'return'], T_0, Y], axis=1)\n",
    "\n",
    "            Y_uplift = df_comp2['Y'].values[:-1]  # outcome of interest\n",
    "            T_uplift = df_comp2['T'].values[:-1]   # intervention, or treatment\n",
    "            X_uplift = df_comp2.drop(columns=['Y', 'T']).values[:-1]   # confounders\n",
    "            xg = XGBTRegressor(random_state=212)\n",
    "            try:\n",
    "                te, lb, ub = xg.estimate_ate(X_uplift, T_uplift, Y_uplift)\n",
    "                X_comp = related_comp\n",
    "                pred_day_X = df.loc[pred_day].loc[X_comp, 'feature'].loc[:, 'return'].values.reshape(1, -1)\n",
    "                effect = xg.predict(pred_day_X)\n",
    "                causal_effect = effect[0, 0]\n",
    "            except:\n",
    "                causal_effect = 0\n",
    "            causal_martix[i, j] = causal_effect\n",
    "    np.save(os.path.join(output_path, pred_day.strftime('%Y-%m-%d') + '.npy'), causal_martix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## high volume with high negative return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = args.save_path + '/' + 'hrhv_neg'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "ts_bgein = datetime.datetime.strptime('2017-01-01', '%Y-%m-%d')\n",
    "\n",
    "for pred_day in tqdm(pred_timestamps):\n",
    "    if pred_day < ts_bgein:\n",
    "        continue\n",
    "    train_start = (pred_day - relativedelta(years=2)).strftime('%Y-%m-%d')\n",
    "    train_end = (pred_day - relativedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    events = {'train':(train_start, train_end),}\n",
    "\n",
    "    ## correlation\n",
    "    dir_adj_np = np.load(args.save_path + '/corr_lim/' + pred_day.strftime('%Y-%m-%d') + '.npy')\n",
    "\n",
    "    ## causal\n",
    "    adj_matrix = pd.DataFrame(dir_adj_np, index=company_sel, columns=company_sel,dtype=bool)\n",
    "    inter = events['train']\n",
    "    day_start = get_interval(inter)[0]\n",
    "    day_end = get_interval(inter)[1]\n",
    "    causal_martix = np.zeros_like(adj_matrix, dtype=np.float64)\n",
    "    for comp in company_sel: # target node\n",
    "        i = company_sel.index(comp)\n",
    "        related_comp = adj_matrix.loc[comp][adj_matrix.loc[comp] == True].index.to_list()\n",
    "        if len(related_comp)==0:\n",
    "            continue\n",
    "        df_comp = df.loc[day_start:day_end].loc[(slice(None), related_comp+[comp]), 'feature'].loc[:, 'return']\n",
    "        df_comp = pd.pivot(df_comp.reset_index(),index='datetime', columns='instrument')\n",
    "        df_vol = df.loc[day_start:day_end].loc[(slice(None), related_comp+[comp]), 'feature'].loc[:, '$volume']\n",
    "        df_vol = pd.pivot(df_vol.reset_index(), index='datetime', columns='instrument')\n",
    "        Y = pd.Series(df_comp.loc[:, 'return'][comp].shift(-1), name='Y')\n",
    "        for T_comp in related_comp:\n",
    "            j = company_sel.index(T_comp)\n",
    "            ## volume\n",
    "            T_vol = pd.Series(df_vol.loc[:, '$volume'][T_comp], name='T').copy(deep=True)\n",
    "            lim_vol = T_vol.mean() + 1 * T_vol.std()\n",
    "            cond_pos = T_vol>=lim_vol\n",
    "            T_vol.where(cond_pos, other=0, inplace=True)\n",
    "            T_vol[T_vol>0.01] = 1\n",
    "            T_vol = T_vol.astype('int')\n",
    "            ## return\n",
    "            T_high = pd.Series(df_comp.loc[:, 'return'][T_comp], name='T').copy(deep=True)\n",
    "            lim_high = -0.04\n",
    "            cond_1 = T_high<=lim_high\n",
    "            T_high.where(cond_1, other=0, inplace=True)\n",
    "            T_high[T_high<-0.0001] = 1\n",
    "            T_high = T_high.astype('int')\n",
    "\n",
    "            T_0 = T_vol & T_high\n",
    "            if T_0.sum()<5:\n",
    "                continue\n",
    "\n",
    "            df_comp2 = pd.concat([df_comp.loc[:, 'return'], T_0, Y], axis=1)\n",
    "\n",
    "            Y_uplift = df_comp2['Y'].values[:-1]  # outcome of interest\n",
    "            T_uplift = df_comp2['T'].values[:-1]   # intervention, or treatment\n",
    "            X_uplift = df_comp2.drop(columns=['Y', 'T']).values[:-1]   # confounders\n",
    "            xg = XGBTRegressor(random_state=212)\n",
    "            try:\n",
    "                te, lb, ub = xg.estimate_ate(X_uplift, T_uplift, Y_uplift)\n",
    "                X_comp = related_comp\n",
    "                pred_day_X = df.loc[pred_day].loc[X_comp, 'feature'].loc[:, 'return'].values.reshape(1, -1)\n",
    "                effect = xg.predict(pred_day_X)\n",
    "                causal_effect = effect[0, 0]\n",
    "            except:\n",
    "                causal_effect = 0\n",
    "            causal_martix[i, j] = causal_effect\n",
    "    np.save(os.path.join(output_path, pred_day.strftime('%Y-%m-%d') + '.npy'), causal_martix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuing rise of return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = args.save_path + '/' + 'conup'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "ts_bgein = datetime.datetime.strptime('2017-02-10', '%Y-%m-%d')\n",
    "\n",
    "for pred_day in tqdm(pred_timestamps):\n",
    "    if pred_day < ts_bgein:\n",
    "        continue\n",
    "    train_start = (pred_day - relativedelta(years=2)).strftime('%Y-%m-%d')\n",
    "    train_end = (pred_day - relativedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    events = {'train':(train_start, train_end),}\n",
    "\n",
    "    ## correlation\n",
    "    dir_adj_np = np.load(args.save_path + '/corr_lim/' + pred_day.strftime('%Y-%m-%d') + '.npy')\n",
    "\n",
    "    ## causal\n",
    "    adj_matrix = pd.DataFrame(dir_adj_np, index=company_sel, columns=company_sel,dtype=bool)\n",
    "    inter = events['train']\n",
    "    day_start = get_interval(inter)[0]\n",
    "    day_end = get_interval(inter)[1]\n",
    "    causal_martix = np.zeros_like(adj_matrix, dtype=np.float64)\n",
    "    for comp in company_sel: # target node\n",
    "        i = company_sel.index(comp)\n",
    "        related_comp = adj_matrix.loc[comp][adj_matrix.loc[comp] == True].index.to_list()\n",
    "        if len(related_comp)==0:\n",
    "            continue\n",
    "        df_comp = df.loc[day_start:day_end].loc[(slice(None), related_comp+[comp]), 'feature'].loc[:, 'return']\n",
    "        df_comp = pd.pivot(df_comp.reset_index(),index='datetime', columns='instrument')\n",
    "        Y = pd.Series(df_comp.loc[:, 'return'][comp].shift(-1), name='Y')\n",
    "        for T_comp in related_comp:\n",
    "            j = company_sel.index(T_comp)\n",
    "            ## conup\n",
    "            T_t = pd.Series(df_comp.loc[:, 'return'][T_comp], name='T').copy(deep=True)\n",
    "            lim = 0\n",
    "            cond_pos = T_t>=lim\n",
    "            T_t.where(cond_pos, other=0, inplace=True)\n",
    "            T_t[T_t>0] = 1\n",
    "            T_t = T_t.astype('int')\n",
    "            T_tsub1 = pd.Series(T_t.shift(1), name='Ttsub1')\n",
    "            T_tsub2 = pd.Series(T_t.shift(2), name='Ttsub2')\n",
    "            T_raw = pd.concat([T_t, T_tsub1, T_tsub2], axis=1).fillna(value=0)\n",
    "            T_raw['conup'] = T_raw.apply(lambda x: sum(x), axis=1)\n",
    "            T_conup = T_raw['conup'].apply(lambda x: 1 if x==3 else 0)\n",
    "\n",
    "            T_0 = pd.Series(T_conup, name='T')\n",
    "            if T_0.sum()<5:\n",
    "                continue\n",
    "\n",
    "            df_comp2 = pd.concat([df_comp.loc[:, 'return'], T_0, Y], axis=1)\n",
    "\n",
    "            Y_uplift = df_comp2['Y'].values[:-1]  # outcome of interest\n",
    "            T_uplift = df_comp2['T'].values[:-1]   # intervention, or treatment\n",
    "            X_uplift = df_comp2.drop(columns=['Y', 'T']).values[:-1]   # confounders\n",
    "            xg = XGBTRegressor(random_state=212)\n",
    "            try:\n",
    "                te, lb, ub = xg.estimate_ate(X_uplift, T_uplift, Y_uplift)\n",
    "                X_comp = related_comp\n",
    "                pred_day_X = df.loc[pred_day].loc[X_comp, 'feature'].loc[:, 'return'].values.reshape(1, -1)\n",
    "                effect = xg.predict(pred_day_X)\n",
    "                causal_effect = effect[0, 0]\n",
    "\n",
    "            except:\n",
    "                causal_effect = 0\n",
    "\n",
    "            causal_martix[i, j] = causal_effect\n",
    "    np.save(os.path.join(output_path, pred_day.strftime('%Y-%m-%d') + '.npy'), causal_martix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuing drop of return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = args.save_path + '/' + 'condown'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "ts_bgein = datetime.datetime.strptime('2017-01-01', '%Y-%m-%d')\n",
    "\n",
    "for pred_day in tqdm(pred_timestamps):\n",
    "    if pred_day < ts_bgein:\n",
    "        continue\n",
    "    train_start = (pred_day - relativedelta(years=2)).strftime('%Y-%m-%d')\n",
    "    train_end = (pred_day - relativedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    events = {'train':(train_start, train_end),}\n",
    "\n",
    "    ## correlation\n",
    "    dir_adj_np = np.load(args.save_path + '/corr_lim/' + pred_day.strftime('%Y-%m-%d') + '.npy')\n",
    "\n",
    "    ## causal\n",
    "    adj_matrix = pd.DataFrame(dir_adj_np, index=company_sel, columns=company_sel,dtype=bool)\n",
    "    inter = events['train']\n",
    "    day_start = get_interval(inter)[0]\n",
    "    day_end = get_interval(inter)[1]\n",
    "    causal_martix = np.zeros_like(adj_matrix, dtype=np.float64)\n",
    "    for comp in company_sel: # target node\n",
    "        i = company_sel.index(comp)\n",
    "        related_comp = adj_matrix.loc[comp][adj_matrix.loc[comp] == True].index.to_list()\n",
    "        if len(related_comp)==0:\n",
    "            continue\n",
    "        df_comp = df.loc[day_start:day_end].loc[(slice(None), related_comp+[comp]), 'feature'].loc[:, 'return']\n",
    "        df_comp = pd.pivot(df_comp.reset_index(),index='datetime', columns='instrument')\n",
    "        Y = pd.Series(df_comp.loc[:, 'return'][comp].shift(-1), name='Y')\n",
    "        for T_comp in related_comp:\n",
    "            j = company_sel.index(T_comp)\n",
    "            ## condown\n",
    "            T_t = pd.Series(df_comp.loc[:, 'return'][T_comp], name='T').copy(deep=True)\n",
    "            lim = 0\n",
    "            cond_pos = T_t<lim\n",
    "            T_t.where(cond_pos, other=0, inplace=True)\n",
    "            T_t[T_t<0] = 1\n",
    "            T_t = T_t.astype('int')\n",
    "            T_tsub1 = pd.Series(T_t.shift(1), name='Ttsub1')\n",
    "            T_tsub2 = pd.Series(T_t.shift(2), name='Ttsub2')\n",
    "            T_raw = pd.concat([T_t, T_tsub1, T_tsub2], axis=1).fillna(value=0)\n",
    "            T_raw['conup'] = T_raw.apply(lambda x: sum(x), axis=1)\n",
    "            T_conup = T_raw['conup'].apply(lambda x: 1 if x==3 else 0)\n",
    "\n",
    "            T_0 = pd.Series(T_conup, name='T')\n",
    "            if T_0.sum()<5:\n",
    "                continue\n",
    "\n",
    "            df_comp2 = pd.concat([df_comp.loc[:, 'return'], T_0, Y], axis=1)\n",
    "\n",
    "            Y_uplift = df_comp2['Y'].values[:-1]  # outcome of interest\n",
    "            T_uplift = df_comp2['T'].values[:-1]   # intervention, or treatment\n",
    "            X_uplift = df_comp2.drop(columns=['Y', 'T']).values[:-1]   # confounders\n",
    "            xg = XGBTRegressor(random_state=212)\n",
    "            try:\n",
    "                te, lb, ub = xg.estimate_ate(X_uplift, T_uplift, Y_uplift)\n",
    "                X_comp = related_comp\n",
    "                pred_day_X = df.loc[pred_day].loc[X_comp, 'feature'].loc[:, 'return'].values.reshape(1, -1)\n",
    "                effect = xg.predict(pred_day_X)\n",
    "                causal_effect = effect[0, 0]\n",
    "            except:\n",
    "                causal_effect = 0\n",
    "            causal_martix[i, j] = causal_effect\n",
    "    np.save(os.path.join(output_path, pred_day.strftime('%Y-%m-%d') + '.npy'), causal_martix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
